{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e Otimização de Modelos para o Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração Inicial e Imports\n",
    "\n",
    "Importação das bibliotecas necessárias e configuração do ambiente, como logs e avisos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import optuna\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple, Type, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", handlers=[logging.StreamHandler(sys.stdout)])\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurações do Projeto\n",
    "\n",
    "Configuração de constantes e caminhos de diretórios necessários para o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Type[Any]\n",
    "\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "ARTIFACTS_DIR = BASE_DIR / \"artifacts\"\n",
    "MODELS_DIR = ARTIFACTS_DIR / \"models\"\n",
    "REPORTS_DIR = BASE_DIR / \"reports\"\n",
    "FIGURES_DIR = REPORTS_DIR / \"figures\" \n",
    "\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE = RAW_DATA_DIR / \"train.csv\"\n",
    "TEST_FILE = RAW_DATA_DIR / \"test.csv\"\n",
    "SUBMISSION_FILE = DATA_DIR / \"submission.csv\"\n",
    "BEST_MODEL_FILE = ARTIFACTS_DIR / \"ensemble_model.joblib\"\n",
    "FE_PIPELINE_FILE = ARTIFACTS_DIR / \"fe_pipeline.joblib\"\n",
    "METRICS_FILE = ARTIFACTS_DIR / \"training_metrics.json\"\n",
    "\n",
    "TARGET_COLUMN: str = \"Survived\"\n",
    "\n",
    "MODELS_TO_TUNE: Dict[str, Model] = {\n",
    "    \"RandomForest\": RandomForestClassifier,\n",
    "    \"GradientBoosting\": GradientBoostingClassifier,\n",
    "    \"XGBClassifier\": XGBClassifier,\n",
    "    \"LGBMClassifier\": LGBMClassifier,\n",
    "    \"SVC\": SVC,\n",
    "}\n",
    "\n",
    "logger.info(f\"Diretório base configurado para: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Engenharia de Features (Pré-processamento)\n",
    "\n",
    "Esta função, antes em `processing/preprocessor.py`, é responsável por criar novas features e tratar valores ausentes a partir do DataFrame bruto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame, bins: Optional[Dict[str, list]] = None) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # tratamento de valores ausentes\n",
    "    if 'Age' in df_copy.columns:\n",
    "        df_copy['Age'].fillna(df_copy['Age'].median(), inplace=True)\n",
    "    if 'Fare' in df_copy.columns:\n",
    "        df_copy['Fare'].fillna(df_copy['Fare'].median(), inplace=True)\n",
    "    if 'Embarked' in df_copy.columns:\n",
    "        df_copy['Embarked'].fillna(df_copy['Embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    # criação da feature 'Title'\n",
    "    df_copy['Title'] = df_copy['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    common_titles = {\"Mr\", \"Miss\", \"Mrs\", \"Master\"}\n",
    "    df_copy['Title'] = df_copy['Title'].apply(lambda x: x if x in common_titles else 'Other')\n",
    "\n",
    "    # criação das features 'FamilySize' e 'IsAlone'\n",
    "    df_copy['FamilySize'] = df_copy['SibSp'] + df_copy['Parch'] + 1\n",
    "    df_copy['IsAlone'] = (df_copy['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # discretização de 'Age' e 'Fare'\n",
    "    if bins:\n",
    "        df_copy['AgeGroup'] = pd.cut(df_copy['Age'], bins=bins['AgeBins'], labels=False, include_lowest=True)\n",
    "        df_copy['FareBin'] = pd.cut(df_copy['Fare'], bins=bins['FareBins'], labels=False, include_lowest=True)\n",
    "    else:\n",
    "        df_copy['AgeGroup'] = pd.cut(df_copy['Age'], bins=[0, 12, 18, 60, np.inf], labels=False, include_lowest=True)\n",
    "        try:\n",
    "            df_copy['FareBin'] = pd.qcut(df_copy['Fare'], 4, labels=False, duplicates='drop')\n",
    "        except ValueError:\n",
    "            # fallback para o caso de não ser possível criar quantis\n",
    "            df_copy['FareBin'] = pd.cut(df_copy['Fare'], 4, labels=False, include_lowest=True)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definição dos Pipelines de Modelagem\n",
    "\n",
    "A função `create_modeling_pipeline` define a estrutura de pré-processamento (scaling para features numéricas e one-hot encoding para categóricas) e o anexa a um classificador para formar um pipeline completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainResult = Tuple[str, Pipeline, float, float, Dict[str, Any]]\n",
    "\n",
    "def create_modeling_pipeline(model: Any) -> Pipeline:\n",
    "    numeric_features = [\"Age\", \"Fare\", \"FamilySize\"]\n",
    "    categorical_features = [\n",
    "        \"Embarked\",\n",
    "        \"Sex\",\n",
    "        \"Pclass\",\n",
    "        \"Title\",\n",
    "        \"IsAlone\",\n",
    "        \"AgeGroup\",\n",
    "        \"FareBin\",\n",
    "    ]\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "    return Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Otimização de Hiperparâmetros com Optuna\n",
    "\n",
    "A função `get_objective_function` cria uma função objetivo para o Optuna. Esta função define o espaço de busca dos hiperparâmetros para cada modelo e retorna a acurácia média da validação cruzada, que o Optuna tentará maximizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objective_function(model_name: str, X: pd.DataFrame, y: pd.Series, models_to_tune: Dict[str, Any]):\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        if model_name == \"RandomForest\":\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 5, 20),\n",
    "                \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            }\n",
    "            model_instance = models_to_tune[model_name](random_state=42, n_jobs=1, **params)\n",
    "        elif model_name == \"GradientBoosting\":\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            }\n",
    "            model_instance = models_to_tune[model_name](random_state=42, **params)\n",
    "        elif model_name == \"SVC\":\n",
    "            params = {\"C\": trial.suggest_float(\"C\", 0.1, 10.0)}\n",
    "            model_instance = models_to_tune[model_name](random_state=42, probability=True, **params)\n",
    "        elif model_name == \"XGBClassifier\":\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            }\n",
    "            model_instance = models_to_tune[model_name](random_state=42, eval_metric=\"logloss\", use_label_encoder=False, **params)\n",
    "        elif model_name == \"LGBMClassifier\":\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
    "            }\n",
    "            model_instance = models_to_tune[model_name](random_state=42, verbose=-1, **params)\n",
    "        else:\n",
    "            raise ValueError(f\"Modelo {model_name} não suportado.\")\n",
    "\n",
    "        pipeline = create_modeling_pipeline(model_instance)\n",
    "        score = cross_val_score(\n",
    "            pipeline, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=\"accuracy\"\n",
    "        ).mean()\n",
    "        return score\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Função de Treinamento de Modelo Individual\n",
    "\n",
    "`train_single_model` encapsula o processo de otimização para um único modelo: cria um estudo do Optuna, executa a otimização, treina o modelo final com os melhores parâmetros e retorna seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_model(model_name: str, X: pd.DataFrame, y: pd.Series, n_trials: int, models_to_tune: Dict[str, Any]) -> TrainResult:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    objective_fn = get_objective_function(model_name, X, y, models_to_tune)\n",
    "    study.optimize(objective_fn, n_trials=n_trials, n_jobs=1, show_progress_bar=False)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    logger.info(f\"Otimização para {model_name} concluída. Melhores parâmetros: {best_params}\")\n",
    "\n",
    "    model_class = models_to_tune[model_name]\n",
    "    if model_name == \"SVC\":\n",
    "        best_params[\"probability\"] = True\n",
    "    elif model_name == \"LGBMClassifier\":\n",
    "        best_params[\"verbose\"] = -1\n",
    "\n",
    "    final_model_instance = model_class(**best_params, random_state=42)\n",
    "    final_pipeline = create_modeling_pipeline(final_model_instance)\n",
    "\n",
    "    cv_scores = cross_val_score(\n",
    "        final_pipeline, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=\"accuracy\"\n",
    "    )\n",
    "    mean_accuracy, std_dev = np.mean(cv_scores), np.std(cv_scores)\n",
    "    \n",
    "    logger.info(f\"Modelo {model_name} validado. Acurácia: {mean_accuracy:.4f} (+/- {std_dev:.4f})\")\n",
    "    final_pipeline.fit(X, y)\n",
    "    \n",
    "    return model_name, final_pipeline, mean_accuracy, std_dev, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Execução Principal do Treinamento\n",
    "\n",
    "Esta é a célula principal que orquestra todo o processo. Primeiro, definimos os parâmetros de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_TO_TRAIN_LIST = list(MODELS_TO_TUNE.keys())\n",
    "N_TRIALS = 1 # número de tentativas de otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Carga e Processamento dos Dados\n",
    "\n",
    "Carregamos os dados de treino e aplicamos o pipeline de engenharia de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "training_metrics: Dict[str, Any] = {\"individual_models\": {}}\n",
    "\n",
    "df = pd.read_csv(str(TRAIN_FILE))\n",
    "logger.info(\"Aplicando engenharia de features...\")\n",
    "\n",
    "fe_pipeline = Pipeline(steps=[('feature_engineering', FunctionTransformer(feature_engineering))])\n",
    "\n",
    "X = df.drop(TARGET_COLUMN, axis=1)\n",
    "y = df[TARGET_COLUMN]\n",
    "X_processed = fe_pipeline.fit_transform(X)\n",
    "\n",
    "joblib.dump(fe_pipeline, FE_PIPELINE_FILE)\n",
    "logger.info(f\"Pipeline de engenharia de features salvo em: {FE_PIPELINE_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Treinamento Paralelo dos Modelos Base\n",
    "\n",
    "Utilizamos `ThreadPoolExecutor` para treinar e otimizar os modelos selecionados em paralelo, acelerando significativamente o processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_tune_filtered = {k: v for k, v in MODELS_TO_TUNE.items() if k in MODELS_TO_TRAIN_LIST}\n",
    "logger.info(f\"Modelos a serem treinados: {list(models_to_tune_filtered.keys())}\")\n",
    "logger.info(f\"Número de trials por modelo: {N_TRIALS}\")\n",
    "\n",
    "results: List[TrainResult] = []\n",
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    futures = {\n",
    "        executor.submit(train_single_model, name, X_processed.copy(), y.copy(), N_TRIALS, models_to_tune_filtered): name\n",
    "        for name in models_to_tune_filtered\n",
    "    }\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        results.append(future.result())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Criação e Treinamento do Modelo Ensemble\n",
    "\n",
    "Selecionamos os 3 melhores modelos base com base na acurácia da validação cruzada. Em seguida, usamos esses modelos como estimadores para um `StackingClassifier`, que é treinado para se tornar o nosso modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results:\n",
    "    logger.error(\"Nenhum modelo foi treinado. Verifique as configurações.\")\n",
    "else:\n",
    "    # seleciona os 3 melhores modelos\n",
    "    top_models: List[TrainResult] = sorted(results, key=lambda item: item[2], reverse=True)[:3]\n",
    "\n",
    "    for name, pipeline, score, std_dev, params in top_models:\n",
    "        model_path = MODELS_DIR / f\"{name.lower()}_model.joblib\"\n",
    "        joblib.dump(pipeline, model_path)\n",
    "        training_metrics[\"individual_models\"][name] = {\"accuracy\": score, \"std_dev\": std_dev, \"params\": params, \"path\": str(model_path)}\n",
    "        logger.info(f\"Modelo {name} salvo com acurácia {score:.4f} (+/- {std_dev:.4f}).\")\n",
    "    \n",
    "    logger.info(\"Iniciando treinamento do modelo Stacking Ensemble...\")\n",
    "    \n",
    "    stacking_estimators = [(name.lower(), model) for name, model, _, _, _ in top_models]\n",
    "    meta_model = LogisticRegression(random_state=42)\n",
    "    stacking_clf = StackingClassifier(estimators=stacking_estimators, final_estimator=meta_model, cv=5, n_jobs=-1)\n",
    "\n",
    "    # valida o modelo\n",
    "    cv_scores = cross_val_score(stacking_clf, X_processed, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=\"accuracy\", n_jobs=-1)\n",
    "    mean_score, std_score = np.mean(cv_scores), np.std(cv_scores)\n",
    "    logger.info(f\"Acurácia do Stacking: {mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "\n",
    "    training_metrics[\"ensemble_model\"] = {\"type\": \"StackingClassifier\", \"accuracy\": mean_score, \"std_dev\": std_score, \"estimators\": [name for name, _, _, _, _ in top_models], \"final_estimator\": type(meta_model).__name__}\n",
    "\n",
    "    logger.info(\"Treinando o Stacking final com todos os dados...\")\n",
    "    stacking_clf.fit(X_processed, y)\n",
    "    joblib.dump(stacking_clf, BEST_MODEL_FILE)\n",
    "    logger.info(f\"Melhor modelo (Ensemble) salvo em: {BEST_MODEL_FILE}\")\n",
    "    \n",
    "    # salva as métricas\n",
    "    training_metrics[\"total_training_time\"] = time.perf_counter() - start_time\n",
    "    with open(METRICS_FILE, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(training_metrics, f, indent=4)\n",
    "    logger.info(f\"Métricas de treinamento salvas em: {METRICS_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Geração do Arquivo de Submissão para o Kaggle\n",
    "\n",
    "Com o melhor modelo treinado (o ensemble), agora o usamos para fazer predições no conjunto de dados de teste (`test.csv`) e formatamos o resultado no arquivo `submission.csv`, pronto para ser enviado ao Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BEST_MODEL_FILE.exists() and FE_PIPELINE_FILE.exists():\n",
    "    logger.info(\"Iniciando a geração do arquivo de submissão...\")\n",
    "    \n",
    "    df_test = pd.read_csv(str(TEST_FILE))\n",
    "    passenger_ids = df_test['PassengerId']\n",
    "    \n",
    "    fe_pipeline_loaded = joblib.load(FE_PIPELINE_FILE)\n",
    "    final_model_loaded = joblib.load(BEST_MODEL_FILE)\n",
    "    \n",
    "    X_test_processed = fe_pipeline_loaded.transform(df_test)\n",
    "    \n",
    "    predictions = final_model_loaded.predict(X_test_processed)\n",
    "    \n",
    "    submission_df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})\n",
    "    submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "    \n",
    "    logger.info(f\"Arquivo de submissão salvo com sucesso em: {SUBMISSION_FILE}\")\n",
    "    display(submission_df.head())\n",
    "else:\n",
    "    logger.error(\"Artefatos de modelo ou pipeline não encontrados. Não foi possível gerar a submissão.\")\n",
    "\n",
    "logger.info(\"Processo de treinamento e submissão concluído.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
